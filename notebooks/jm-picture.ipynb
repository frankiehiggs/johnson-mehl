{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519357f0-6803-4577-987f-0119f0b9c551",
   "metadata": {},
   "source": [
    "# Johnson-Mehl tessellation picture\n",
    "\n",
    "I'd like to draw a picture of the Johnson-Mehl tessellation and a Voronoi tessellation so the viewer can compare them.\n",
    "\n",
    "One interesting fact which I hadn't realised until trying to draw these pictures: the boundaries between cells in the JM tessellation _aren't straight_.\n",
    "\n",
    "I've used the algorithm described by Moulinec in [\"A simple and fast algorithm for computing discrete Voronoi, Johnson-Mehl or Laguerre diagrams of points\"](https://www.sciencedirect.com/science/article/pii/S0965997822000618). Mainly because it's simple, although being fast is also an advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615ccc0-45e5-48ee-8e58-fbf0a816b97f",
   "metadata": {},
   "source": [
    "## To do:\n",
    "1. Draw the \"tessellation\" when the radii are too small to cover the whole space, with uncovered areas. This is a pretty minor change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b6812-80ae-4f5c-9fc1-7fd64fde6be8",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Sample the arrival times and locations, and prune them.\n",
    "2. Assign each pixel in an image to its appropriate cell, based on which Johnson-Mehl seed grows to cover it first.\n",
    "3. Compute adjacency: I want to know which cells border each other so I can colour them appropriately.\n",
    "4. Colour the cells nicely. It's a planar map, so a four-colouring exists, but I think I'll be a bit simpler and use a greedy colouring, so no two neighbouring cells share a colour but maybe the number of colours isn't completely optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788447b4-e5ec-4155-9239-9cdefe3c4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from unconstrained import sample_points, prune_arrivals\n",
    "from tqdm import trange\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3322-73f3-4f42-87e1-0a20057a43f6",
   "metadata": {},
   "source": [
    "### Sampling arrival times and pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrival_times( rho, max_time=1.0, R=0 ):\n",
    "    # PROBLEM (major-ish):\n",
    "    # The \"start again if there are more than Nmax arrivals\" method\n",
    "    # means our arrival times don't exactly have the distribution of homogeneous\n",
    "    # Poisson arrivals. Instead I suppose I should generate some new samples.\n",
    "    rate = rho*(1+2*R)**2\n",
    "    Nmax = int(max_time*rate + 2*np.sqrt(max_time*rate)) # Two standard deviations above the mean\n",
    "    interarrival_times = np.random.exponential(scale=1/rate,size=Nmax)\n",
    "    arrival_times = np.cumsum(interarrival_times)\n",
    "    too_late = np.searchsorted(arrival_times,max_time,side='right') # First index where the arrival time is at least max_time\n",
    "    while too_late == Nmax: # This will be the case if we are unlucky and Nmax points arrived before time max_time. We'll just generate more points.\n",
    "        interarrival_times = np.append(interarrival_times, np.random.exponential(scale=1/rate,size=Nmax))\n",
    "        arrival_times = np.cumsum(interarrival_times)\n",
    "        too_late = np.searchsorted(arrival_times,max_time,side='right') # First index where the arrival time is at least max_time\n",
    "    return arrival_times[:too_late].copy()\n",
    "    # N = np.random.poisson(lam=rho*max_time*(1+2*R)**2)\n",
    "    # return np.sort(np.random.uniform(low=0.0, high=max_time, size=N))\n",
    "# # Needed redefining because of my foolishly using a global variable (rng)\n",
    "# # to define the version of this function in unconstrained.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b970c8c-6756-458a-b049-dd7a28c117e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 10\n",
    "\n",
    "times = get_arrival_times(rho)\n",
    "seeds = sample_points(len(times))\n",
    "arrived = prune_arrivals(times, seeds)\n",
    "print(f'{len(arrived)} out of {len(times)} seeds germinated.')\n",
    "times = times[arrived]\n",
    "seeds = seeds[arrived]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd095f1-5519-4041-a77c-d7c206a218cd",
   "metadata": {},
   "source": [
    "If I try to take $\\rho$ larger than around $5 \\times 10^7$, the kernel dies (presumably from running out of memory).\n",
    "\n",
    "Is it possible to add points in batches? It should be... We just need to merge two sorted lists (easy) and rearrange the list of locations to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88343626-eee1-42cc-a2e2-f950cdd40c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_jm_arrivals(t1,l1,t2,l2):\n",
    "    \"\"\"\n",
    "    Given two sets of arrival times and locations from a time-homogeneous PPP,\n",
    "    merges them into a single pair.\n",
    "\n",
    "    The arguments are all numpy arrays, and both t1 and t2 should be sort\n",
    "    \"\"\"\n",
    "    totallen = len(t1)+len(t2)\n",
    "    outtimes = np.empty(totallen)\n",
    "    outseeds = np.empty((totallen,2))\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    while i1 < len(t1) and i2 < len(t2):\n",
    "        if t1[i1] < t2[i2]:\n",
    "            outtimes[i1+i2] = t1[i1]\n",
    "            outseeds[i1+i2] = l1[i1]\n",
    "            i1 += 1\n",
    "        else:\n",
    "            outtimes[i1+i2] = t2[i2]\n",
    "            outseeds[i1+i2] = l2[i2]\n",
    "            i2 += 1\n",
    "    if i1 == len(t1):\n",
    "        outtimes[i1+i2:] = t2[i2:]\n",
    "        outseeds[i1+i2:] = l2[i2:]\n",
    "    else:\n",
    "        outtimes[i1+i2:] = t1[i1:]\n",
    "        outseeds[i1+i2:] = l1[i1:]\n",
    "    return outtimes, outseeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b51253-f1a9-443e-9e77-64ded2a5527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rho = 1.0e5\n",
    "n_batches = 100\n",
    "rho = batch_rho * n_batches\n",
    "max_time = 1.5*( (2*np.log(rho) + 4*np.log(np.log(rho))) / (np.pi*rho) )**(1/3)\n",
    "display(f'Running until max time {max_time:.5f}.')\n",
    "times = get_arrival_times(batch_rho,max_time=max_time)\n",
    "seeds = sample_points(len(times))\n",
    "arrived = prune_arrivals(times, seeds)\n",
    "times = times[arrived]\n",
    "seeds = seeds[arrived]\n",
    "progress = trange(n_batches-1)\n",
    "for i in progress:\n",
    "    progress.set_description(\"Finding new arrivals\")\n",
    "    new_times = get_arrival_times(batch_rho,max_time=max_time)\n",
    "    new_seeds = sample_points(len(new_times))\n",
    "    progress.set_description(\"Pruning new arrivals\")\n",
    "    arrived = prune_arrivals(new_times, new_seeds)\n",
    "    new_times = new_times[arrived]\n",
    "    new_seeds = new_seeds[arrived]\n",
    "    progress.set_description(\"Merging all arrivals\")\n",
    "    times, seeds = merge_jm_arrivals(times,seeds,new_times,new_seeds) # Is it faster to just stick all the arrays together and sort them at the end? (Since we don't prune in the middle any more.)\n",
    "    progress.set_description(\"Merged. Weird pause.\")\n",
    "    # if len(times) >= 1000000:\n",
    "    #     progress.set_description(\"We have a huge list, pruning as an intermediate step...\")\n",
    "    #     arrived = prune_arrivals(times,seeds)\n",
    "    #     times = times[arrived]\n",
    "    #     seeds = seeds[arrived]\n",
    "print(\"Arrivals all generated, now for the last pruning...\") # There's a weird pause after the loop but before this message is printed. Not sure why.\n",
    "arrived = prune_arrivals(times,seeds)\n",
    "times = times[arrived]\n",
    "seeds = seeds[arrived]\n",
    "print(f'We have a total of {len(seeds)} arrivals with rate {rho} (that\\'s {rho:.0e}).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c6652-15d1-4659-b932-abc3bc84d70c",
   "metadata": {},
   "source": [
    "#### Idea to speed this up a bit more:\n",
    "Currently we merge and prune an increasingly large list.\n",
    "A better idea might be a sort of binary recursive structure.\n",
    "Merge generation 1 arrival processes to get the generation 2 processes,\n",
    "then merge the generation 2 processes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8832a-b1b5-4382-8cc2-e4400a538810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_sampling(batch_rho, generations, prune_limit=1000000):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d9b8a-569c-4a1e-b618-dd9ffeaa39b1",
   "metadata": {},
   "source": [
    "### Assigning pixels to their cells\n",
    "\n",
    "This is the bit using Moulinec's method. Moulinec has two separate steps: first assigning the pixels which are covered by time $T$, then the pixels which were not covered by time $T$. He chooses $T$ to optimise the speed of the algorithm. We can simplify the algorithm by choosing $T$ to be the coverage time, then there is no second step.\n",
    "\n",
    "---\n",
    "\n",
    "The algorithm works as follows: we start with an array $\\mathcal{D}$ of \"running minimum coverage times\" and an array $\\mathcal{I}$ of assignments, both the same shape as the output image. We intialise $\\mathcal{D}$ to be full of $\\infty$. We order the seeds $x_1, \\dots, x_N$ with corresponding arrival times $t_1, \\dots, t_N$.\n",
    "\n",
    "Then for each $i = 1, \\dots, N$ in turn: for every pixel $y$ in the ball centred at $x_i$ of radius $T-t_i$, this pixel was first reached by seed $i$ at time $\\| x_i - y \\| + t_i$. If $\\| x_i - y \\| + t_i < \\mathcal{D}(y)$, then we set $\\mathcal{I}(y) = i$ (overwriting its previous value if it had one) and set the new running minimum $\\mathcal{D}(y) = \\| x_i - y \\| + t_i$.\n",
    "\n",
    "Once we have done this for all $N$ seeds, every pixel is correctly assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25545dae-409c-4734-82d1-08bec4d3ec3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_ball_pixels(centre, radius, img_size):\n",
    "    \"\"\"\n",
    "    Returns the indices of the pixels in the picture\n",
    "    corresponding to a ball centred at a point in [0,1]^2\n",
    "    of a given radius.\n",
    "    Also saves the corresponding (squared) distances.\n",
    "    \n",
    "    I suspect a numpy-ish method would be faster:\n",
    "    create a 2d array containing the (squared) distance between each point in [min_i,max_i]x[min_j,max_j]\n",
    "    and v, then turn that into an array of bools which we can return along with the distances.\n",
    "    We might need to also then return (min_i, min_j) so the bool array can be aligned within the image.    \n",
    "    \"\"\"\n",
    "    if radius <= 0:\n",
    "        return [], []\n",
    "    v = (img_size-1)*centre\n",
    "    x,y = v[0], v[1]\n",
    "    r = (img_size-1)*radius\n",
    "    r2 = r*r\n",
    "    min_i = max( 0, int(x-r) )\n",
    "    max_i = min( img_size-1, int(x+r)+1 )\n",
    "    min_j = max( 0, int(y-r) )\n",
    "    max_j = min( img_size-1, int(y+r)+1 )\n",
    "    in_ball = []\n",
    "    sq_distances = []\n",
    "    for i in range(min_i, max_i+1):\n",
    "        dx2 = (x-i)*(x-i)\n",
    "        if dx2 > r2:\n",
    "            continue\n",
    "        w = np.sqrt( r2 - dx2 )\n",
    "        for j in range(max(int(y-w),min_j), min(int(y+w)+2,max_j+1)):\n",
    "            d2 = dx2 + (y-j)**2\n",
    "            if d2 <= r2:\n",
    "                in_ball.append((i,j))\n",
    "                sq_distances.append(d2)\n",
    "    return in_ball, sq_distances\n",
    "\n",
    "def assign_cells( seeds, times, img_size, T=1.0 ):\n",
    "    \"\"\"\n",
    "    Assigns all the pixels in an img_size x img_size picture\n",
    "    to their respective Johnson-Mehl cells.\n",
    "    T should be a decent upper bound on the coverage time - smaller T\n",
    "    means we check fewer points.\n",
    "    This is a modified version of Moulinec's algorithm,\n",
    "    in which we assign things which were covered by time T,\n",
    "    and leave the rest unassigned.\n",
    "    \"\"\"\n",
    "    min_cov_times = np.full((img_size,img_size),np.inf) # running minimum coverage times\n",
    "    assignments = np.full((img_size,img_size),-1,dtype=int) # everything uncovered is assigned to a separate class.\n",
    "\n",
    "    for i in trange(len(times)):\n",
    "        xi = seeds[i]\n",
    "        ti = times[i]\n",
    "        indices, d2s = get_ball_pixels(xi, T-ti, img_size)\n",
    "        for k, ij_pair in enumerate(indices):\n",
    "            cov_time = np.sqrt(d2s[k])/img_size + ti\n",
    "            if cov_time < min_cov_times[ij_pair]:\n",
    "                assignments[ij_pair] = i\n",
    "                min_cov_times[ij_pair] = cov_time\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c616c6-9f82-4d9e-8e85-b64d4ce50bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 1920\n",
    "\n",
    "max_time = 1.5*( (2*np.log(rho) + 4*np.log(np.log(rho))) / (np.pi*rho) )**(1/3)\n",
    "I = assign_cells(seeds, times, img_size, T=max_time)\n",
    "# print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114f6a4-6e2b-4746-b520-afe052ba387f",
   "metadata": {},
   "source": [
    "### Computing adjacency\n",
    "\n",
    "The method is easy: for each pixel check if its cell differs from the one below and the one to the right. If they differ, then record the pair of cell IDs in the adjacency matrix. This might be a little slow, but this is miles faster than assigning the pixels in the first place. As long as the resolution is high enough this will, with high probability, give us the correct adjacency structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b81004-1077-46a5-a7e9-b4729704274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx # Contains a Graph object which we'll use to store the cell structure.\n",
    "def get_adjacency(cell_assignments, blanklabel=-1):\n",
    "    G = networkx.Graph()\n",
    "    #G.add_nodes_from(range(cell_assignments.max()+1)) # Uncomment this to include cells with zero pixels\n",
    "    N = cell_assignments.shape[0]\n",
    "    for i in range(N-1): # All columns except the last\n",
    "        for j in range(N-1): # All rows except the last\n",
    "            G.add_edge(cell_assignments[i,j], cell_assignments[i+1,j])\n",
    "            G.add_edge(cell_assignments[i,j], cell_assignments[i,j+1])\n",
    "        G.add_edge(cell_assignments[i,N-1],cell_assignments[i+1,N-1])\n",
    "    for j in range(N-1):\n",
    "        G.add_edge(cell_assignments[N-1,j],cell_assignments[N-1,j+1])\n",
    "    G.remove_edges_from(networkx.selfloop_edges(G)) # Not necessary for the colouring but if we want to look at the graph structure it makes it a bit cleaner.\n",
    "    G.remove_nodes_from([blanklabel]) # If there are uncovered cells, remove them from the adjacency graph.\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39abc1-0be5-4442-9c00-91e33332ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_structure = get_adjacency(I)\n",
    "# networkx.draw(cell_structure, with_labels=False, node_size=20)\n",
    "print(cell_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f8a19-ca00-4850-9d37-70d1749fd122",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def colour_graph(G):\n",
    "    \"\"\"\n",
    "    Uses a greedy algorithm to colour G.\n",
    "    The \"colours\" are just integers, which can be replaced\n",
    "    with a suitable set of colours when drawing the picture later.\n",
    "    Even with a few thousand cells I've never seen it use more than\n",
    "    7 colours.\n",
    "\n",
    "    Returns a dictionary indexed by the elements of G.nodes\n",
    "    \"\"\"\n",
    "    cells = list(G.nodes).copy()\n",
    "    colours = dict.fromkeys(G.nodes)\n",
    "    \n",
    "    np.random.shuffle(cells)\n",
    "    for cell in cells:\n",
    "        new_colour = 0\n",
    "        while new_colour in [colours[v] for v in G.neighbors(cell)]:\n",
    "            new_colour += 1\n",
    "        colours[cell] = new_colour\n",
    "    return colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfddd6-9256-44ea-8fe9-b64e8f6c6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normally it's possible to find a 5-colouring in a few thousand tries, which is pretty quick.\n",
    "# # There is a non-zero (but rather small) probability that you'll get a 4-colouring, if you're feeling patient.\n",
    "colours = colour_graph(cell_structure)\n",
    "\n",
    "# i=1\n",
    "# while max(colours.values())+1 > 6:\n",
    "#     colours = colour_graph(cell_structure)\n",
    "#     i+=1\n",
    "# print(f'{i} attempts to get a {max(colours.values())+1}-colouring.')\n",
    "\n",
    "print(f'We have a {len(set(colours.values()))}-colouring of the cells.')\n",
    "# networkx.draw(cell_structure, node_size=50, node_color=list(colours.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d4d66-8397-4cab-b9f7-7c979c7b9ad8",
   "metadata": {},
   "source": [
    "Next we pick suitable colours.\n",
    "\n",
    "I might two independent colourings of the cells,\n",
    "so we have colours of the same luminosity and change the brightnesses.\n",
    "This means it will be a colourful diagram on the screen but will still have a valid colouring when printed in greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e0875-2f08-4dee-a38b-5093e65eda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorspace\n",
    "c = colorspace.hcl_palettes().get_palette(name=\"Reds 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b731c3-9472-42eb-bb6f-d970287c9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageColor\n",
    "\n",
    "hex_colours = c(max(colours.values())+1) # The last colour is for unassigned regions.\n",
    "rgb_colours = [ImageColor.getcolor(col,\"RGB\") for col in hex_colours]\n",
    "bg_colour = (252, 15,192)\n",
    "\n",
    "data = np.full((img_size, img_size, 3),0, dtype=np.uint8)\n",
    "N = I.shape[0]\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if I[i,j] >= 0:\n",
    "            data[i,j,:] = rgb_colours[colours[I[i,j]]]\n",
    "        else:\n",
    "            data[i,j,:] = bg_colour\n",
    "\n",
    "image = Image.fromarray(data)\n",
    "# image.show() # opens in system image viewer\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d522e39-5b2a-49b8-851a-5483640c2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
